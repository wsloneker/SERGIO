{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from SERGIO.sergio import sergio\n",
    "import random\n",
    "import networkx as nx\n",
    "from pyvis.network import Network\n",
    "import graphviz\n",
    "from scipy import stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Based on: De-noised_100G_3T_300cPerT_dynamics_8_DS8\n",
    "# (100 Genes, 3 Cell Types, 300 Cells Per Type, 900 Total Cells)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start simulating new level\n",
      "There are 3 genes to simulate in this layer\n",
      "Done with current level\n",
      "Start simulating new level\n",
      "There are 7 genes to simulate in this layer\n",
      "Done with current level\n",
      "Start simulating new level\n",
      "There are 90 genes to simulate in this layer\n",
      "Done with current level\n"
     ]
    }
   ],
   "source": [
    "sim = sergio(number_genes=100, number_bins = 3, number_sc = 300, noise_params = 1, decays=0.8, sampling_state=15, noise_type='dpd')\n",
    "sim.build_graph(input_file_taregts ='data_sets/De-noised_100G_3T_300cPerT_dynamics_8_DS8/Interaction_cID_8_1.txt', \n",
    "                input_file_regs='data_sets/De-noised_100G_3T_300cPerT_dynamics_8_DS8/Regs_cID_8.txt', shared_coop_state=2)\n",
    "sim.simulate()\n",
    "expr = sim.getExpressions()\n",
    "expr_clean = np.concatenate(expr, axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[2 0 2 ... 1 0 2]\n",
      " [0 0 1 ... 0 0 0]\n",
      " [1 2 1 ... 1 1 1]\n",
      " ...\n",
      " [2 1 2 ... 2 2 0]\n",
      " [0 1 3 ... 0 4 1]\n",
      " [0 4 1 ... 2 0 2]]\n"
     ]
    }
   ],
   "source": [
    "expr_O = sim.outlier_effect(expr, outlier_prob = 0.01, mean = 0.8, scale = 1)\n",
    "libFactor, expr_O_L = sim.lib_size_effect(expr_O, mean = 4.6, scale = 0.4)\n",
    "binary_ind = sim.dropout_indicator(expr_O_L, shape = 6.5, percentile = 0)\n",
    "expr_O_L_D = np.multiply(binary_ind, expr_O_L)\n",
    "count_matrix = sim.convert_to_UMIcounts(expr_O_L_D)\n",
    "count_matrix = np.concatenate(count_matrix, axis = 1)\n",
    "print(count_matrix)\n",
    "np.save('FeaturesSet1.npy', count_matrix.T)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "sz = count_matrix.shape\n",
    "for i in range(0, sz[0]):\n",
    "    curr = count_matrix[i, :]\n",
    "    ct = 0\n",
    "    for j in range(0, sz[1]):\n",
    "        if curr[j] != 0:\n",
    "            ct += 1\n",
    "    if ct == sz[1]:\n",
    "        print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "sz = count_matrix.shape\n",
    "for i in range(0, sz[1]):\n",
    "    curr = count_matrix[:, i]\n",
    "    ct = 0\n",
    "    for j in range(0, sz[0]):\n",
    "        if curr[j] != 0:\n",
    "            ct += 1\n",
    "    if ct == sz[0]:\n",
    "        print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start simulating new level\n",
      "There are 3 genes to simulate in this layer\n",
      "Done with current level\n",
      "Start simulating new level\n",
      "There are 7 genes to simulate in this layer\n",
      "Done with current level\n",
      "Start simulating new level\n",
      "There are 90 genes to simulate in this layer\n",
      "Done with current level\n"
     ]
    }
   ],
   "source": [
    "sim = sergio(number_genes=100, number_bins = 3, number_sc = 300, noise_params = 1, decays=0.8, sampling_state=15, noise_type='dpd')\n",
    "sim.build_graph(input_file_taregts ='data_sets/De-noised_100G_3T_300cPerT_dynamics_8_DS8/Interaction_cID_8_2.txt', \n",
    "                input_file_regs='data_sets/De-noised_100G_3T_300cPerT_dynamics_8_DS8/Regs_cID_8.txt', shared_coop_state=2)\n",
    "sim.simulate()\n",
    "expr = sim.getExpressions()\n",
    "expr_clean = np.concatenate(expr, axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1 0 0 ... 3 0 1]\n",
      " [0 0 1 ... 0 1 0]\n",
      " [2 0 1 ... 1 3 0]\n",
      " ...\n",
      " [2 1 1 ... 0 1 4]\n",
      " [0 0 0 ... 0 0 0]\n",
      " [0 0 3 ... 0 1 0]]\n"
     ]
    }
   ],
   "source": [
    "expr_O = sim.outlier_effect(expr, outlier_prob = 0.01, mean = 0.8, scale = 1)\n",
    "libFactor, expr_O_L = sim.lib_size_effect(expr_O, mean = 4.6, scale = 0.4)\n",
    "binary_ind = sim.dropout_indicator(expr_O_L, shape = 6.5, percentile = 0)\n",
    "expr_O_L_D = np.multiply(binary_ind, expr_O_L)\n",
    "count_matrix = sim.convert_to_UMIcounts(expr_O_L_D)\n",
    "count_matrix = np.concatenate(count_matrix, axis = 1)\n",
    "print(count_matrix)\n",
    "np.save('FeaturesSet2.npy', count_matrix.T)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "sz = count_matrix.shape\n",
    "for i in range(0, sz[0]):\n",
    "    curr = count_matrix[i, :]\n",
    "    ct = 0\n",
    "    for j in range(0, sz[1]):\n",
    "        if curr[j] != 0:\n",
    "            ct += 1\n",
    "    if ct == sz[1]:\n",
    "        print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "sz = count_matrix.shape\n",
    "for i in range(0, sz[1]):\n",
    "    curr = count_matrix[:, i]\n",
    "    ct = 0\n",
    "    for j in range(0, sz[0]):\n",
    "        if curr[j] != 0:\n",
    "            ct += 1\n",
    "    if ct == sz[0]:\n",
    "        print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df1 = pd.read_csv('data_sets/De-noised_100G_3T_300cPerT_dynamics_8_DS8/gt_GRN.csv')\n",
    "l1 = list(df1['P1'])\n",
    "l2 = list(df1['P2'])\n",
    "np.save('data_sets/De-noised_100G_3T_300cPerT_dynamics_8_DS8/gt_GRN1.npy', [l1, l2])\n",
    "df2 = pd.read_csv('data_sets/De-noised_100G_3T_300cPerT_dynamics_8_DS8/gt_GRN2.csv')\n",
    "l1 = list(df2['P1'])\n",
    "l2 = list(df2['P2'])\n",
    "np.save('data_sets/De-noised_100G_3T_300cPerT_dynamics_8_DS8/gt_GRN2.npy', [l1, l2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2, 137) (2, 137)\n",
      "251 251 251\n"
     ]
    }
   ],
   "source": [
    "gt1 = np.load('data_sets/De-noised_100G_3T_300cPerT_dynamics_8_DS8/gt_GRN1.npy')\n",
    "gt2 = np.load('data_sets/De-noised_100G_3T_300cPerT_dynamics_8_DS8/gt_GRN2.npy')\n",
    "print(gt1.shape, gt2.shape)\n",
    "s = set()\n",
    "lst1 = []\n",
    "lst2 = []\n",
    "for i in range(0, gt1.shape[1]):\n",
    "    p1 = gt1[0, i]\n",
    "    p2 = gt1[1, i]\n",
    "    if (p1, p2) not in s:\n",
    "        lst1.append(p1)\n",
    "        lst2.append(p2)\n",
    "        s.add((p1, p2))\n",
    "for i in range(0, gt2.shape[1]):\n",
    "    p1 = gt2[0, i]\n",
    "    p2 = gt2[1, i]\n",
    "    if (p1, p2) not in s:\n",
    "        lst1.append(p2)\n",
    "        lst2.append(p2)\n",
    "        s.add((p1, p2))\n",
    "print(len(lst1), len(lst2), len(s))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "251\n"
     ]
    }
   ],
   "source": [
    "np.save('FullEdgeIndex.npy', [lst1, lst2])\n",
    "print(len(lst1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def create_comp_graph(feat, corr, edge1, edge2):\n",
    "    '''Get a graph based on highly correlated features (feat) and given correlation (corr).'''\n",
    "    X = feat.T # Transpose feature matrix to be gene x cell --> we want highly correlated GENES not cells/patients :)\n",
    "    s_l = []\n",
    "    d_l = []\n",
    "    s1 = set()\n",
    "    for i in range(0, edge1.shape[1]):\n",
    "        p1 = edge1[0, i]\n",
    "        p2 = edge1[1, i]\n",
    "        s1.add((p1, p2))\n",
    "    s2 = set()\n",
    "    shared = set()\n",
    "    for i in range(0, edge2.shape[1]):\n",
    "        p1 = edge2[0, i]\n",
    "        p2 = edge2[1, i]\n",
    "        if (p1, p2) in s1:\n",
    "            shared.add((p1, p2))\n",
    "        else:\n",
    "            s2.add((p1, p2))\n",
    "    s1 = set()\n",
    "    for i in range(0, edge1.shape[1]):\n",
    "        p1 = edge1[0, i]\n",
    "        p2 = edge1[1, i]\n",
    "        if (p1, p2) not in shared:\n",
    "            s1.add((p1, p2))\n",
    "    ct1 = 0\n",
    "    ct2 = 0\n",
    "    share = 0\n",
    "    for i in range(X.shape[0]):\n",
    "        for j in range(X.shape[0]):\n",
    "            if i != j:\n",
    "                res = abs(stats.pearsonr(X[i, :], X[j, :])[0]) # Get the correlation between each gene\n",
    "                if res >= corr:\n",
    "                    s_l.append(i)\n",
    "                    d_l.append(j)\n",
    "                    if (i, j) in s1:\n",
    "                        ct1 += 1\n",
    "                    if (i, j) in s2:\n",
    "                        ct2 += 1\n",
    "                    if (i, j) in shared:\n",
    "                        share += 1\n",
    "    print(f\"Number of Edges: {len(s_l)}\") # Prints # of edges so you can make sure it isn't empty/too large\n",
    "    print(ct1, ct2, share)\n",
    "    edge_index = np.array([s_l, d_l]) # Convert to array\n",
    "    return edge_index # Return edge index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of Edges: 2238\n",
      "20 28 13\n"
     ]
    }
   ],
   "source": [
    "a = np.load('FeaturesSet1.npy')\n",
    "b = np.load('FeaturesSet2.npy')\n",
    "features = np.concatenate((a, b), axis=0)\n",
    "res = create_comp_graph(features, 0.15, gt1, gt2) # Generate correlation graph based on correlation\n",
    "filename = 'CorrelationEdgeIndex'\n",
    "np.save(f'{filename}.npy', res) # Save edge index as .npy file to run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of Edges: 9900\n",
      "114 114 23\n"
     ]
    }
   ],
   "source": [
    "res = create_comp_graph(features, 0, gt1, gt2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(900, 100)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(900, 100)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "ys = []\n",
    "for i in range(0, 300):\n",
    "    ys.append(0)\n",
    "for i in range(0, 300):\n",
    "    ys.append(1)\n",
    "for i in range(0, 300):\n",
    "    ys.append(2)\n",
    "np.save('Y1.npy', ys)\n",
    "np.save('Y2.npy', ys)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# df = pd.read_csv('data_sets/De-noised_100G_3T_300cPerT_dynamics_8_DS8/gt_GRN.csv')\n",
    "# regs = [90, 79, 5, 1, 18, 9]\n",
    "# g = Network(notebook=True, directed=True)\n",
    "# ei1 = list(df['P1'])\n",
    "# ei2 = list(df['P2'])\n",
    "# b1 = []\n",
    "# b2 = []\n",
    "# n = []\n",
    "# c = []\n",
    "# for i in range(len(ei1)):\n",
    "#     b1.append(ei1[i])\n",
    "#     b2.append(ei2[i])\n",
    "# u1 = np.unique(b1)\n",
    "# u2 = np.unique(b2)\n",
    "# for i in u1:\n",
    "#     if i not in n:\n",
    "#         n.append(i)\n",
    "#         if i not in regs:\n",
    "#             c.append('black')\n",
    "#         else:\n",
    "#             c.append('pink')\n",
    "# for i in u2:\n",
    "#     if i not in n:\n",
    "#         n.append(i)\n",
    "#         if i not in regs:\n",
    "#             c.append('black')\n",
    "#         else:\n",
    "#             c.append('pink')\n",
    "# g.add_nodes(n, color=c)\n",
    "# for i in range(0, len(b1)):\n",
    "#     g.add_edge(b1[i], b2[i])\n",
    "# for edge in g.get_edges():\n",
    "#     p1 = edge['from']\n",
    "#     p2 = edge['to']\n",
    "#     edge[\"color\"] = 'black'\n",
    "# g.show('gt_GRN.html')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
